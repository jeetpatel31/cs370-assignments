{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drone follow me using Kalman Filters\n",
    "\n",
    "Multi-Object Tracking (MOT) is a core visual ability that humans poses to perform kinetic tasks and coordinate other tasks. The AI community has recognized the importance of MOT via a series of [competitions](https://motchallenge.net). \n",
    "\n",
    "In this assignment, the object class is `bicycle` and `car` the ability to track these objects  will be demonstrated using [Kalman Filters](https://en.wikipedia.org/wiki/Kalman_filter).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Setup your development environment and store the test video locally (10 points)\n",
    "\n",
    "Your environment must be docker based and you can use any TF2 or PT2 based docker container compatible with your environment. You can also use colab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Object Detection (40 points)\n",
    "\n",
    "Perform object detection on the following videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the videos into frames and use an object detector of your choice, in a framework of your choice to detect the cyclists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "def initialize_kalman_filter():\n",
    "    kf = KalmanFilter(dim_x=4, dim_z=2)\n",
    "    kf.F = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "    kf.H = np.array([[1, 0, 0, 0], [0, 1, 0, 0]])\n",
    "    kf.R *= 10\n",
    "    kf.P *= 1000\n",
    "    kf.Q = np.eye(kf.dim_x) * 0.01\n",
    "    return kf\n",
    "\n",
    "def select_objects(frame):\n",
    "    objects = []\n",
    "    print(\"Select objects and press ENTER or SPACE when done. Press 'c' to cancel the current selection.\")\n",
    "    while True:\n",
    "        roi = cv2.selectROI(\"Frame\", frame, fromCenter=False, showCrosshair=True)\n",
    "        if roi == (0, 0, 0, 0):\n",
    "            break\n",
    "        kf = initialize_kalman_filter()\n",
    "        objects.append([roi, kf, [], None])\n",
    "    cv2.destroyAllWindows()\n",
    "    return objects\n",
    "\n",
    "def track_objects(frame, objects):\n",
    "    for object in objects:\n",
    "        roi = object[0]\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        tracker.init(frame, roi)\n",
    "        object[3] = tracker\n",
    "\n",
    "def update_trackers(objects, frame):\n",
    "    for object in objects:\n",
    "        tracker = object[3]\n",
    "        success, box = tracker.update(frame)\n",
    "        if success:\n",
    "            p1 = (int(box[0]), int(box[1]))\n",
    "            p2 = (int(box[0] + box[2]), int(box[1] + box[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "            center = (p1[0] + (p2[0] - p1[0]) // 2, p1[1] + (p2[1] - p1[1]) // 2)\n",
    "            object[2].append(center)\n",
    "            object[1].update(np.array([[center[0]], [center[1]]]))\n",
    "\n",
    "def main(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video\")\n",
    "        return\n",
    "    \n",
    "    objects = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        update_trackers(objects, frame)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "        key = cv2.waitKey(30) & 0xFF\n",
    "        if key == ord('p'):\n",
    "            selected_objects = select_objects(frame)\n",
    "            objects.extend(selected_objects)\n",
    "            track_objects(frame, selected_objects)\n",
    "        elif key == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"Cyclist and vehicle Tracking - 2.mp4\"\n",
    "    main(video_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click on the Thumbnail it will open sample video on my youtube chanal. I wanted to put the video here but since storage is limited I can not uploaded on Git.\n",
    "\n",
    "[![Video Title](1.PNG)](https://youtu.be/bZ4jAOuXk0Y \"Video Title - Click to Watch!\")\n",
    "[![Video Title](2.PNG)](https://youtu.be/bZ4jAOuXk0Y \"Video Title - Click to Watch!\")\n",
    "[![Video Title](3.PNG)](https://youtu.be/RuykFveCeaE \"Video Title - Click to Watch!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Kalman Filter (50 points)\n",
    "\n",
    "Use the  [filterpy](https://filterpy.readthedocs.io/en/latest/kalman/KalmanFilter.html) library to implement Kalman filters that will track the cyclist and the vehicle (if present) in the video. You will need to use the detections from the previous task to initialize and run the Kalman filter. \n",
    "\n",
    "You need to deliver a video that contains the trajectory of the objects as a line that connects the pixels that the tracker indicated. You can use the `ffmpeg` command line tool and OpenCV to superpose the bounding box of the drone on the video as well as plot its trajectory. \n",
    "\n",
    "Suggest methods that you can use to address  false positives and how the tracker can help you in this regard.\n",
    "\n",
    "You will need to have one Kalman filter to track each of the required and present objects (cyclist and vehicle).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
